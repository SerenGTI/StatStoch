\chapter{Multivariate}
Bisher wurden nur eindimensionale Daten erfasst, nicht aber verschschiedene Merkmale in Zusammenhang gebracht und gemeinsam betrachtet oder miteinander verglichen.
\section{Kontingenztafel}\label{kontingenztafel}
Die Kontingenztabelle eignet sich zu Darstellung der gemeinsamen Verteilung von zwei Diskreten Merkmalen mit relativ wenigen Ausprägungen.

Auf Basis der Ausprägungen $a_1,\ldots,a_k$ des Merkmals $X$ und $b_1,\ldots,b_m$ für $Y$ liegen in der Urliste die gemeinsamen Messwerte vor. Das heißt die Urliste besteht aus den Tupeln $(a_i,b_j)$. Analog zum Eindimensionalen sind die absoluten Häufigkeiten $h_{ij}$ definiert. Darauf aufbauend ebenfalls völlig analog die relativen Häufigkeiten $f_{ij}$.

\paragraph{Kontingenztafel der absoluten Häufigkeiten}
Die aus diesen Werten entstehende Tafel heißt $(k\times m)$-Kontingenztafel der absoluten Häufigkeiten. Sie enthält neben den Häufigkeitsdaten zusätzlich noch die Spalten- beziehungsweise Zeilensummen der Werte.

\begin{center}
	\begin{tabular}{c|ccc|c}
		& $b_1$ & $\cdots$ & $b_m$ &\\
		\hline $a_1$ & $h_{11}$ & $\cdots$ & $h_{1m}$&$h_{1\cdot}=\sum_{i=1}^m h_{1i}$\\
		$a_2$ & $h_{21}$ & $\cdots$ & $h_{2m}$&$h_{2\cdot}=\sum_{i=1}^m h_{2i}$\\
		$\vdots$ & $\vdots$ & $\cdots$ & $\vdots$&\\
		$a_1$ & $h_{k1}$ & $\cdots$ & $h_{km}$&$h_{k\cdot}=\sum_{i=1}^m h_{ki}$\\
		\hline &$h_{\cdot1}$&&$h_{\cdot m}$&$n$
	\end{tabular}
\end{center}

Die Zeilensummen $h_{i\cdot}$ werden auch als Randhäufigkeiten des Merkmals $X$ bezeichnet. Diese Werte sind die einfachen Häufigkeiten mit denen das Merkmal $X$ die Werte $a_1,\ldots,a_k$ annimmt, wenn $Y$ nicht berücksichtigt wird.

Analog dazu sind die Spaltensummen die Häufigkeiten von $Y$ unter Vernachlässigung des Merkmals $X$.

\paragraph{Kontingenztafel der relativen Häufigkeiten}
Da Anteile beziehungsweise Prozente häufig anschaulicher sind als absolute Häufigkeitswerte betrachtet man häufig auch die Häufigkeitstafel der relativen Häufigkeiten. Diese entsteht durch teilen durch die Gesamtzahl $n$.

\begin{center}
	\begin{tabular}{c|ccc|c}
		& $b_1$ & $\cdots$ & $b_m$ &\\
		\hline $a_1$ & $h_{11}$ & $\cdots$ & $h_{1m}$&$f_{1\cdot}=\sum_{i=1}^m f_{1i}$\\
		$a_2$ & $f_{21}$ & $\cdots$ & $f_{2m}$&$f_{2\cdot}=\sum_{i=1}^m f_{2i}$\\
		$\vdots$ & $\vdots$ & $\cdots$ & $\vdots$&\\
		$a_1$ & $f_{k1}$ & $\cdots$ & $f_{km}$&$f_{k\cdot}=\sum_{i=1}^m f_{ki}$\\
		\hline &$f_{\cdot1}$&&$f_{\cdot m}$&$1$
	\end{tabular}
\end{center}

\section{Bedingte Häufigkeiten}
Aus den gemeinsamen Häufigkeiten lässt sich nicht direkt auf den Zusammenhang zweier Merkmale schließen.
So kann man ein Merkmal fest wählen und dann die Häufigkeitsverteilung des anderen Merkmals unabhängig davon betrachten, mit dieser Herangehensweise kommt man zu den bedingten Häufigkeiten.

\begin{definition}{Bedingte Häufigkeiten}
	Für zwei Merkmale $X$ und $Y$ mit den Ausprägungen $a_1,\ldots,a_k$ und $b_1,\ldots,b_m$ ist
	\begin{equation*}
		f_Y(b_j|a_i)=\frac{h_{ij}}{h_i}
	\end{equation*}
	die Häufigkeit des Merkmals $b_j$ aus $Y$ unter der Bedingung $X=a_i$.

	Daraus geht durch die Werte 
	\begin{equation*}
		f_Y(b_1|a_i),\ \ldots,\ f_Y(b_m|a_i)
	\end{equation*}
	die bedingte Häufigkeitsverteilung von $Y$ unter der Bedingung $X=a_i$ (Kurzschreibweise: $(Y|X=a_i)$) hervor.

	Analog für eine fest gewählte Ausprägung $Y=b_i$ die bedingte Häufigkeitsverteilung $f_X(a_j|b_i)$.
\end{definition}


\section{Zusammenhangsmaße}
Wir betracten zunächst wie sich zwei Merkmale zueinander verhalten würden, wenn keinerlei Zusammenhang zwischen ihnen bestünde.

In einer Kontingenztafel müssten sich dann die einzelnen Spalten proportional zu den Spaltensummen verhalten und analog die Zeilen zu den Zeilensummen.
Daraus ergibt sich die \emph{erwartete Häufigkeit einer Ausprägung bei unabhängigen Merkmalen} $X$ und $Y$
\begin{equation*}
	\tilde h_{ij}=\frac{h_{i*}*h_{*j}}{n}
\end{equation*}

Um den Zusammenhang zweier Merkmale zu untersuchen betrachten wir also den Unterschied zwischen den tatsächlichen Häufigkeiten $h_{ij}$ und den jeweils erwarteten Häufigkeiten $\tilde h_{ij}$.

\subsection{$\chi^2$-Koeffizient}
Basierend auf der oben angesprochenen Differenz wird das erste Zusammenhangsmaß konstruiert.
\begin{definition}{$\chi^2$-Koeffizient}
	Für zwei Merkmale $X$ und $Y$ mit den Ausprägungen $a_1,\ldots,a_k$ und $b_1,\ldots,b_m$ ist
	\begin{equation*}
		\chi^2 = \sum\limits_{i=1}^k\sum\limits_{j=1}^m\frac{(h_{ij}-\tilde h_{ij})^2}{\tilde h_{ij}}\quad \chi^2\in[0,\infty)
	\end{equation*}
\end{definition}

Ist $\chi^2$ groß, weichen die Häufigkeiten also stark von der Erwartung ab, hängen die Merkmale vermutlich voneinander ab. Sind die Abweichungen allerdings relativ klein und damit $\chi^2$ ebenfalls, so sind die Merkmale wahrscheinlich unabhängig. Selbst bei unabhängigen Merkmalen ist meist wegen zufälligem Rauschen $\chi^2\neq0$, eine Entscheidung ist so also nicht möglich.

\subsection{Kontingenzkoeffizient}
Problematisch am $\chi^2$-Koeffizienten ist die Abhängigkeit von der Dimension der Tafel. Es kann nicht ohne weiteres aus dem Wert des Koeffizienten auf eine Unabhängigkeit der Merkmale geschlossen werden.

Als erster Normierungsschritt folgt daraus der Kontingenzkoeffizient.
\begin{definition}{Kontingenzkoeffizient}
	Aus dem $\chi^2$-Koeffizienten für zwei Merkmale mit der Urliste der Größe $n$ ist der Kontingenzkoeffizient
	\begin{equation*}
		K=\sqrt{\frac{\chi^2}{n+\chi^2}} \quad K\in[0, K_{\mathrm{max}}] \text{ für } K_{\mathrm{max}}=\sqrt{\frac{M-1}{M}},\enspace M=\max\simpleset{m,k}
	\end{equation*}
	Dabei seien $m$ und $k$ die Mächtigkeit der Ausprägungsliste der beiden Merkmale.
\end{definition}

\paragraph{Korrigierter Kontingenzkoeffizient}
Da auch dieser für einen sinnvollen Vergleich nicht ausreichend normiert ist, wird der korrigierte Kontingenzkoeffizient eingeführt, wobei $K$ durch $K_{\mathrm{max}}$ normiert wird.
\begin{equation*}
	K^\ast = \frac{K}{K_{\mathrm{max}}}\quad K^\ast \in [0,1]
\end{equation*}

Sowohl der Kontingenzkoeffizient als auch der $\chi^2$-Koeffizient stellen nur die Stärke des Zusammenhangs dar, nicht aber eine Richtung der Wirkungsweise. 

\subsection{Empirischer Korrelationskoeffizient (Bravais-Pearson)}
Um nicht nur die Stärke des Zusammenhangs zu untersuchen sondern auch die Richtung der Wirkungsweise, wird der empirische Korrelationskoeffizient auf metrischen Merkmalen eingeführt.
\begin{definition}{Emp. Korrelationskoeffizient nach Bravais-Pearson}
	Für zwei metrische Merkmale $X$ und $Y$ auf einer Urliste der Größe $n$ ist der empirische Korrelationskoeffizient
	\begin{equation*}
		r=\frac{\frac1n\sum\limits_{i=1}^n (x_i-\overline x)(y_i-\overline y)}{\sqrt{\frac1n\sum\limits_{i=1}^n (x_i-\overline x)^2} * \sqrt{\frac1n\sum\limits_{i=1}^n (y_i-\overline y)^2}}=\frac{\tilde s_{XY}}{\tilde s_X*\tilde s_Y}
	\end{equation*}
	wobei $\tilde s_X$ bzw. $\tilde s_Y$ die Standardabweichungen der Merkmale $X$ und $Y$ sind.
\end{definition}
Der Korrelationskoeffizient misst die Stärke des linearen Zusammenhangs.
Damit ergibt sich für $r>0$ eine positive Korrelation also ein gleichsinniger Zusammenhang und ein gegensinniger Zusammenhang für $r<0$. Bei $r\approx0$ sind die Merkmale nicht korreliert.

\paragraph{Empirische Kovarianz}
Die Kovarianz ist die Summe der Abweichungsprodukte mit $n$ normiert.
\begin{equation*}
	\tilde s_{XY}=\frac1n\sum\limits_{i=1}^n (x_i-\overline x)(y_i-\overline y)
\end{equation*}

\paragraph{Rechengünstige Variante des Korrelationskoeffizienten}
\begin{equation*}
	r=\frac{\sum\limits_{i=1}^n (x_iy_i)-n\overline x\overline y}{\sqrt{\left(\sum\limits_{i=1}^n x_i^2 -n\overline x^2\right)*\left(\sum\limits_{i=1}^n y_i^2 -n\overline y^2\right)}}
\end{equation*}

\subsection{$\phi$-Koeffizient}
Für Merkmale mit nur zwei Ausprägungen (\emph{dichotome} oder \emph{binäre} Merkmale) wird der Bravis-Pearson-Koeffizient auch $\phi$-Koeffizient genannt. Er berechnet sich aus den Häufigkeitseinträgen der Kontingenztafel
\begin{equation*}
	r=\frac{h_{11}*h_{22}-h_{12}*h_{21}}{\sqrt{h_{1*}h_{2*}h_{*1}h_{*2}}}=\phi
\end{equation*}
Es gilt sogar zusätzlich
\begin{equation*}
	\phi^2=\frac{\chi^2}{n}
\end{equation*}